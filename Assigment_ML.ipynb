{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assigment_ML.ipynb","provenance":[],"mount_file_id":"1RM0KT8tdOfCvFM3qId-0GAAo6XS2nGNM","authorship_tag":"ABX9TyP+HEuJ4qhHaCpxE89jstrf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y74yAp4OBKQb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1593052057411,"user_tz":-420,"elapsed":8850,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"5c6e197b-77df-4aa7-de89-70679baf85ee"},"source":["!pip install mahotas"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting mahotas\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/1f/01d805bc3588da8343373c279702d0fca4dc55f631873d9f2e159f9287ac/mahotas-1.4.10-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 2.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n","Installing collected packages: mahotas\n","Successfully installed mahotas-1.4.10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JAvwnz3OwoVa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593052075271,"user_tz":-420,"elapsed":2744,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"094ebe8d-552e-4057-fbe1-c6b52d8186ae"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","import cv2\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers import Dense, Activation, Dropout, Flatten\n","\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from keras.layers.normalization import BatchNormalization\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras import regularizers\n","import cv2\n","import mahotas"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Np2sFMvyrTKZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593058463954,"user_tz":-420,"elapsed":912,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["#-----------------------------------\n","# GLOBAL FEATURE EXTRACTION\n","#-----------------------------------\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import mahotas\n","import cv2\n","import os\n","import h5py\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFRJxbpkyQrN","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066796,"user_tz":-420,"elapsed":18194,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["base_dir='/content/drive/My Drive/data/trainning/'\n","train_dir=os.path.join(base_dir,'train/')\n","validation_dir=os.path.join(base_dir,'validation/')\n","train_up_dir=os.path.join(train_dir,'up')\n","train_down_dir=os.path.join(train_dir,'down')\n","train_right_dir=os.path.join(train_dir,'right')\n","train_left_dir=os.path.join(train_dir,'left')\n","\n","validation_up_dir=os.path.join(validation_dir,'up')\n","validation_down_dir=os.path.join(validation_dir,'down')\n","validation_right_dir=os.path.join(validation_dir,'right')\n","validation_left_dir=os.path.join(validation_dir,'left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvT0vwkKzipd","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066796,"user_tz":-420,"elapsed":18189,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["num_up_tr=len(os.listdir(train_up_dir))\n","num_down_tr=len(os.listdir(train_down_dir))\n","num_right_tr=len(os.listdir(train_right_dir))\n","num_left_tr=len(os.listdir(train_left_dir))\n","\n","num_up_val=len(os.listdir(validation_up_dir))\n","num_down_val=len(os.listdir(validation_down_dir))\n","num_right_val=len(os.listdir(validation_right_dir))\n","num_left_val=len(os.listdir(validation_left_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ju7D2Uyk0Kkj","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066797,"user_tz":-420,"elapsed":18185,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["total_train=num_up_tr+num_down_tr+num_right_tr+num_left_tr\n","total_val=num_up_val+num_down_val+num_right_val+num_left_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlNAP_HB0nDf","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066798,"user_tz":-420,"elapsed":18165,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["print(\"Total train: \",total_train)\n","print(\"Total validation : \",total_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBv9NDYJ2Gs-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593058471021,"user_tz":-420,"elapsed":1424,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["def fd_histogram(image, mask=None):\n","    # chuyển về không gian màu HSV\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n","    # normalize histogram\n","    cv2.normalize(hist, hist)\n","    return hist.flatten()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYXntk-Y2HeQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593058471024,"user_tz":-420,"elapsed":1306,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["def fd_hu_moments(image):\n","    # chuyển về ảnh gray\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n","    return feature"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFPWRAY02MjQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593058471590,"user_tz":-420,"elapsed":1099,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["def fd_haralick(image):\n","    # chuyển về ảnh gray\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    haralick = mahotas.features.haralick(gray).mean(axis=0)\n","    return haralick"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0yU1Iaw2d4L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593058479936,"user_tz":-420,"elapsed":1200,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"58598ba1-560c-4af1-9b0a-f969a2fd5fc2"},"source":["output_path = \"/content/drive/My Drive/data/output\"\n","\n","# path to training data\n","train_path = \"/content/drive/My Drive/data/trainning/train\"\n","\n","# get the training labels\n","train_labels = os.listdir(train_path)\n","train_labels.sort()\n","print(train_labels)\n","\n","# num of images per class\n","images_per_class = 900\n","\n","# fixed-sizes for image\n","fixed_size = tuple((720,1280))\n","\n","# bins for histogram\n","bins = 8\n","\n","# empty lists to hold feature vectors and labels\n","global_features = []\n","labels = []\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['down', 'left', 'right', 'up']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GIS5xyrP3It5","colab_type":"code","colab":{}},"source":["for training_name in train_labels:\n","    # join the training data path and each species training folder\n","    dir = os.path.join(train_path, training_name)\n","     # get the current training label\n","    current_label = training_name\n","    x=os.listdir(dir)\n","    x=np.array(x)\n","    x.reshape(1,-1)\n","    for i in x:\n","      file=os.path.join(dir,i)\n","      print(file)\n","      image = cv2.imread(file)\n","       # Global Feature extraction\n","      fv_hu_moments = fd_hu_moments(image)\n","      fv_haralick   = fd_haralick(image)\n","      fv_histogram  = fd_histogram(image)\n","      ###################################\n","        # Concatenate global features\n","        ###################################\n","      global_feature = np.hstack([fv_histogram, fv_hu_moments, fv_haralick])\n","      # update the list of labels and feature vectors\n","      labels.append(current_label)\n","      global_features.append(global_feature)\n","    print(\"[STATUS] processed folder: {}\".format(current_label))\n","\n","print(\"[STATUS] completed Global Feature Extraction...\")\n","\n","\n","# get the overall feature vector size\n","print (\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\n","\n","# get the overall training label size\n","print (\"[STATUS] training Labels {}\".format(np.array(labels).shape))\n","\n","# encode the target labels\n","le = LabelEncoder()\n","target = le.fit_transform(labels)\n","\n","# normalize the feature vector in the range (0-1)\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","rescaled_features = scaler.fit_transform(global_features)\n","\n","# save the feature vector using HDF5\n","h5f_data = h5py.File(output_path+'data.h5', 'w')\n","h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n","\n","h5f_label = h5py.File(output_path+'labels.h5', 'w')\n","h5f_label.create_dataset('dataset_1', data=np.array(target))\n","\n","h5f_data.close()\n","h5f_label.close()\n","\n","print(\"[STATUS] end of training..\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sBbNi3r3U4f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1593059087713,"user_tz":-420,"elapsed":1524,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"eb5626af-ae0b-45d4-818a-d4de311b8aec"},"source":["\n","#-----------------------------------\n","# TRAINING OUR MODEL\n","#-----------------------------------\n","import h5py\n","import numpy as np\n","import os\n","import glob\n","import cv2\n","import warnings\n","from matplotlib import pyplot\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.externals import joblib\n","\n","warnings.filterwarnings('ignore')\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oxQuqgMuuU-w","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593059387782,"user_tz":-420,"elapsed":3159,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["# path to output\n","output_path = \"/content/drive/My Drive/data/output\"\n","\n","# fixed-sizes for image\n","fixed_size = tuple((720, 1280))\n","\n","# no.of.trees for Random Forests\n","num_trees = 300\n","# bins for histogram\n","bins = 8\n","\n","# num of images per class\n","images_per_class = 900;\n","\n","# import the feature vector and trained labels\n","h5f_data = h5py.File(output_path+'data.h5', 'r')\n","h5f_label = h5py.File(output_path+'labels.h5', 'r')\n","\n","global_features_string = h5f_data['dataset_1']\n","global_labels_string = h5f_label['dataset_1']\n","\n","global_features = np.array(global_features_string)\n","global_labels = np.array(global_labels_string)\n","\n","h5f_data.close()\n","h5f_label.close()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTaHZVY-vW_u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593059722119,"user_tz":-420,"elapsed":1776,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"6b45a47b-c05f-4470-e2c0-39bdd3041b13"},"source":["# create all the machine learning models\n","seed=9\n","# no.of.trees for Random Forests\n","num_trees = 300\n","scoring    = \"accuracy\"\n","models = []\n","models.append(('LR', LogisticRegression(random_state=seed)))\n","models.append(('LDA', LinearDiscriminantAnalysis()))\n","models.append(('KNN', KNeighborsClassifier()))\n","models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n","models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n","models.append(('NB', GaussianNB()))\n","models.append(('SVM', SVC(random_state=seed)))\n","\n","# variables to hold the results and names\n","results = []\n","names   = []\n","\n","# verify the shape of the feature vector and labels\n","print(\"[STATUS] features shape: {}\".format(global_features.shape))\n","print(\"[STATUS] labels shape: {}\".format(global_labels.shape))\n","\n","print(\"[STATUS] training started...\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[STATUS] features shape: (3600, 532)\n","[STATUS] labels shape: (3600,)\n","[STATUS] training started...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n853o8BMwIcr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":412},"executionInfo":{"status":"ok","timestamp":1593059782111,"user_tz":-420,"elapsed":56506,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"0528fcfa-2d91-447a-e609-9d0d9bff5338"},"source":["# 10-fold cross validation\n","for name, model in models:\n","    kfold = KFold(n_splits=10, random_state=seed)\n","    cv_results = cross_val_score(model, global_features,global_labels, cv=kfold, scoring=scoring)\n","    results.append(cv_results)\n","    names.append(name)\n","    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","    print(msg)\n","\n","# boxplot algorithm comparison\n","fig = pyplot.figure()\n","fig.suptitle('Machine Learning algorithm comparison')\n","ax = fig.add_subplot(111)\n","pyplot.boxplot(results)\n","ax.set_xticklabels(names)\n","pyplot.show()\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["LR: 0.865278 (0.143277)\n","LDA: 0.907778 (0.092194)\n","KNN: 0.797778 (0.169876)\n","CART: 0.716667 (0.195414)\n","RF: 0.798056 (0.192390)\n","NB: 0.751389 (0.200113)\n","SVM: 0.855556 (0.131914)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"8QGK5GI0xAgE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593059995861,"user_tz":-420,"elapsed":2245,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}},"outputId":"040b23f9-ac9f-477d-b584-bdfa584b6188"},"source":["clf  = LinearDiscriminantAnalysis()\n","clf.fit(global_features, global_labels)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n","                           solver='svd', store_covariance=False, tol=0.0001)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"cYpOcWWR2BKR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593063412627,"user_tz":-420,"elapsed":1243,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["# save the model to disk\n","import pickle\n","filename = 'finalized_model.sav'\n","pickle.dump(clf, open(filename, 'wb'))"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWr0ryj4xz8o","colab_type":"code","colab":{}},"source":["# path to test data\n","test_path = \"/content/drive/My Drive/data/test\"\n","# get the training labels\n","test_labels = os.listdir(test_path)\n","global_features_test=[]\n","# sort the training labels\n","test_labels.sort()\n","print(test_labels)\n","# loop through the test images\n","test_features = []\n","test_results = []\n","for testing_name in test_labels:\n","    # join the training data path and each species training folder\n","    dir = os.path.join(test_path, testing_name)\n","\n","    # get the current training label\n","    current_label = testing_name\n","    # loop over the images in each sub-folder\n","    x=os.listdir(dir)\n","    x=np.array(x)\n","    x.reshape(1,-1)\n","    for i in x:\n","        file=os.path.join(dir,i)\n","        # print(file)\n","        image = cv2.imread(file)\n","        image = cv2.resize(image, fixed_size)\n","        ####################################\n","        fv_hu_moments = fd_hu_moments(image)\n","        fv_haralick   = fd_haralick(image)\n","        fv_histogram  = fd_histogram(image)\n","\n","        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n","\n","        # scale features in the range (0-1)\n","        scaler = MinMaxScaler(feature_range=(0, 1))\n","        global_feature=global_feature.reshape(1,-1)\n","        rescaled_feature = scaler.fit_transform(global_feature)\n","\n","        # predict label of test image\n","        prediction = clf.predict(rescaled_feature.reshape(1,-1))[0]\n","\n","        # show predicted label on image\n","        cv2.putText(image, train_labels[prediction], (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n","\n","        # display the output image\n","        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","        plt.show()\n","print (\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\n","# # predict label of test image\n","# le = LabelEncoder()\n","# y_result = le.fit_transform(test_results)\n","# y_pred = clf.predict(test_features)\n","# print(y_pred)\n","# print(\"Result: \", (y_pred == y_result).tolist().count(True)/len(y_result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c57hWQZ00wUS","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066803,"user_tz":-420,"elapsed":18101,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["BATCH_SIZE=100\n","EPOCHS=50\n","IMG_SHAPEX=720\n","IMG_SHAPEY=1280\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEco_fh71HiC","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066803,"user_tz":-420,"elapsed":18088,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["image_gen_train=ImageDataGenerator(rescale=1./255)\n","train_data_gen=image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n","                                                   directory=train_dir,\n","                                                   shuffle=True,\n","                                                   target_size=(IMG_SHAPEX,IMG_SHAPEY))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGEMRaOS14N7","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066804,"user_tz":-420,"elapsed":18078,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["image_gen_val=ImageDataGenerator(rescale=1./255)\n","val_data_gen=image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n","                                                   directory=validation_dir,\n","                                                   target_size=(IMG_SHAPEX,IMG_SHAPEY))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0MqH3QA2Rbr","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066804,"user_tz":-420,"elapsed":18068,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["model = Sequential()\n","model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(IMG_SHAPEX, IMG_SHAPEY, 3)))\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(4, activation='softmax'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yp3pm5nu2W8O","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066805,"user_tz":-420,"elapsed":18065,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["model.compile(loss='sparse_categorical_crossentropy'\n","    , optimizer='adam'\n","    , metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VswFKIJO2b4o","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066805,"user_tz":-420,"elapsed":18055,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDIBsuTQ2dnc","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066806,"user_tz":-420,"elapsed":18052,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["history = model.fit_generator(train_data_gen, epochs=EPOCHS,\n","                    steps_per_epoch=total_train//BATCH_SIZE,\n","                    validation_data=val_data_gen,\n","                    validation_steps=total_val//BATCH_SIZE\n","                    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V93Fx05ufBLv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066806,"user_tz":-420,"elapsed":18044,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["!pip install -q --upgrade ipython\n","!pip install -q --upgrade ipykernel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8vIIpWzggvvy","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066807,"user_tz":-420,"elapsed":18004,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["!pip install -q --upgrade ipython==5.5.0\n","!pip install -q --upgrade ipykernel==4.6.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxL0tqtcg9uI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066808,"user_tz":-420,"elapsed":18002,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["!python -m pip install tensorflow-gpu==1.15\n","\n","!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n","!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n","!apt-get update\n","!apt-get install cuda=9.0.176-1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxMOOB4EhXiN","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066808,"user_tz":-420,"elapsed":18000,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["!cat /var/log/colab-jupyter.log"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nm3jLWQih3a","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066809,"user_tz":-420,"elapsed":17997,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3jIlsKfq6Ow","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593052265392,"user_tz":-420,"elapsed":1829,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["\n","\n","class SimpleDatasetLoader:\n","    def __init__(self, preprocessors=None):\n","        # store the image preprocessor\n","        self.preprocessors = preprocessors\n","\n","        # if preprocessors are None, initialize them as an empty list\n","        if self.preprocessors is None:\n","            self.preprocessors = []\n","        \n","    def load(self, imagePaths, verbose=-1):\n","        # initialize the list of features and labels\n","        data = []\n","        labels = []\n","\n","        # loop over the input images\n","        for (i, imagePath) in enumerate(imagePaths):\n","            # load the image and extract the class labels \n","            # format: /path/to/dataset/{class label}/{image}.jpg\n","            image = cv2.imread(imagePath)\n","            label = imagePath.split(os.path.sep)[-2]\n","            \n","            # check to see if preprocessors are not None\n","            if self.preprocessors is not None:\n","                # loop over the preprocessors and apply each to image\n","                for p in self.preprocessors:\n","                    image = p.preprocess(image)\n","            \n","            # upadate the data list followed by the labels\n","            data.append(image)\n","            labels.append(label)\n","\n","            # show an update every 'verbose' image on screen\n","            if verbose > 0 and i > 0 and (i+1)%verbose == 0:\n","                print(\"[INFO] processed {}/{}\".format(i + 1, len(imagePaths)))\n","\n","        # return a tuple of the data and labels\n","        return (np.array(data), np.array(labels))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkeJXdPurZdZ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593052066795,"user_tz":-420,"elapsed":18202,"user":{"displayName":"Quynh Nguyen Lam","photoUrl":"","userId":"04203273030778480574"}}},"source":["imagePaths = list(paths.list_images(\"Dataset Leaf\"))"],"execution_count":null,"outputs":[]}]}