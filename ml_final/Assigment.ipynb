{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roihog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7WEqmqA4ksa",
        "colab_type": "text"
      },
      "source": [
        "### Bài toán nhận diện hướng ngón tay đưa vào dự đoán hướng đi của rắn trong game rắn săn mồi.\n",
        "###Input bài toán là hình ảnh ngón tay cái trỏ các hướng trái, phải, trên, xuống.\n",
        "###Output là hướng của ngón tay và hướng con rắn di chuyển"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zLtPK1QqEQK",
        "colab_type": "text"
      },
      "source": [
        "## Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHFZ0fRABeoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "import h5py\n",
        "import numpy as np\n",
        "import glob\n",
        "import warnings\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGMViIx2Bi7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/drive/My Drive/new_dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hG6MjDwBk23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5b163a9-57e7-4eae-ad98-9eb9f754e91c"
      },
      "source": [
        "data_name=os.listdir(path)\n",
        "data_name.sort()\n",
        "print(data_name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['kaggle', 'quynh', 'san', 'tri', 'trung']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdzAItRTqObq",
        "colab_type": "text"
      },
      "source": [
        "## Extract feature \n",
        "### Hình dáng bàn tay\n",
        "### Hướng ngón tay\n",
        "### Sử dụng HOG cho hình chữ nhật đứng bao quanh bàn tay\n",
        "### Số feature=9x9x4x9=2916"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BrvuFiSss7P",
        "colab_type": "text"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://i.postimg.cc/52F47Kj1/download-1.png' />\n",
        "<figcaption>vẽ bounding box </figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP6eePfvBmsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(img):\n",
        "  contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnt = max(contours, key = lambda x: cv2.contourArea(x))\n",
        "  x,y,w,h = cv2.boundingRect(cnt)\n",
        "  #focus roi\n",
        "  roi = img[y:y+h, x:x+w]\n",
        "  roi = cv2.resize(roi, (150, 150))\n",
        "  H = hog(roi, orientations=9, pixels_per_cell=(15, 15),cells_per_block=(2,2), transform_sqrt=True, block_norm=\"L1\")\n",
        "  return np.hstack(H)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivl6Kkqdqbz-",
        "colab_type": "text"
      },
      "source": [
        "### Tiền xử lí dữ liệu, chuyển các ảnh về ảnh nhị phân, áp dụng hàm extract feature vào từng ảnh thu được vector feature và vector label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYbSq5DteOx",
        "colab_type": "text"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://i.postimg.cc/Ss4mcMH7/t-i-xu-ng.png' />\n",
        "<figcaption>binary image </figcaption></center>\n",
        "</figure>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRr9eawBoQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "cba3826d-2000-4c20-aab7-3f8954fe2d16"
      },
      "source": [
        "global_features = []\n",
        "labels          = []\n",
        "fixed_size=(320,320)\n",
        "for name in data_name:\n",
        "  if name=='quynh':\n",
        "    thresh=125\n",
        "  elif name=='tri':\n",
        "    thresh=95\n",
        "  elif name=='san':\n",
        "    thresh=25\n",
        "  elif name=='trung':\n",
        "    thresh=110\n",
        "  else:\n",
        "    thresh=0\n",
        "  name_path=os.path.join(path,name)\n",
        "  parentid=os.listdir(name_path)\n",
        "  parentid.sort()\n",
        "  for parent in parentid:\n",
        "    parent_path=os.path.join(name_path,parent)\n",
        "    items=os.listdir(parent_path)\n",
        "    items=np.array(items)\n",
        "    items.reshape(1,-1)\n",
        "    for item in items:\n",
        "      file=os.path.join(parent_path,item)\n",
        "      image=cv2.imread(file)\n",
        "      image = cv2.resize(image, fixed_size)\n",
        "      frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      ret,img = cv2.threshold(frame,thresh,255,0)\n",
        "      feature=extract_feature(img)\n",
        "      global_features.append(feature)\n",
        "      labels.append(parent)\n",
        "  print(\"[STATUS] processed folder: {}\".format(name))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[STATUS] processed folder: kaggle\n",
            "[STATUS] processed folder: quynh\n",
            "[STATUS] processed folder: san\n",
            "[STATUS] processed folder: tri\n",
            "[STATUS] processed folder: trung\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG3Mq-g4BqEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h5_data          = '/content/drive/My Drive/inputhog/data.h5'\n",
        "h5_labels       = '/content/drive/My Drive/inputhog/labels.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxnxd1eGrOXW",
        "colab_type": "text"
      },
      "source": [
        "### encode label sau đó lưu vector features và vector label vào file h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Q27D8KBr3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c5211dfd-b434-4c91-9e59-31336f7f4a65"
      },
      "source": [
        "\n",
        "# get the overall feature vector size\n",
        "print(\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\n",
        "\n",
        "# get the overall training label size\n",
        "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))\n",
        "\n",
        "# encode the target labels\n",
        "targetNames = np.unique(labels)\n",
        "le          = LabelEncoder()\n",
        "target      = le.fit_transform(labels)\n",
        "print(\"[STATUS] training labels encoded...\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"[STATUS] target labels: {}\".format(target))\n",
        "print(\"[STATUS] target labels shape: {}\".format(target.shape))\n",
        "\n",
        "\n",
        "# save the feature vector using HDF5\n",
        "h5f_data = h5py.File(h5_data, 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(global_features))\n",
        "\n",
        "h5f_label = h5py.File(h5_labels, 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "print(\"[STATUS] end of training..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[STATUS] feature vector size (18800, 2916)\n",
            "[STATUS] training Labels (18800,)\n",
            "[STATUS] training labels encoded...\n",
            "[STATUS] target labels: [0 0 0 ... 3 3 3]\n",
            "[STATUS] target labels shape: (18800,)\n",
            "[STATUS] end of training..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYu6bIqoBt4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c1736637-df3c-4a9e-94f4-41bdf887a58e"
      },
      "source": [
        "h5f_data  = h5py.File(h5_data, 'r')\n",
        "h5f_label = h5py.File(h5_labels, 'r')\n",
        "\n",
        "global_features_string = h5f_data['dataset_1']\n",
        "global_labels_string   = h5f_label['dataset_1']\n",
        "\n",
        "global_features = np.array(global_features_string)\n",
        "global_labels   = np.array(global_labels_string)\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "# verify the shape of the feature vector and labels\n",
        "print(\"[STATUS] features shape: {}\".format(global_features.shape))\n",
        "print(\"[STATUS] labels shape: {}\".format(global_labels.shape))\n",
        "\n",
        "print(\"[STATUS] training started...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[STATUS] features shape: (18800, 2916)\n",
            "[STATUS] labels shape: (18800,)\n",
            "[STATUS] training started...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHzYoHylrmLm",
        "colab_type": "text"
      },
      "source": [
        "### Split tập dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLNrB_AIBvjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "98b5b08d-028c-4e2e-9698-8bb7a123a677"
      },
      "source": [
        "\n",
        "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
        "                                                                                          np.array(global_labels),\n",
        "                                                                                          test_size=0.2,\n",
        "                                                                                          random_state=42)\n",
        "\n",
        "print(\"[STATUS] splitted train and test data...\")\n",
        "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
        "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
        "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
        "print(\"Test labels : {}\".format(testLabelsGlobal.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[STATUS] splitted train and test data...\n",
            "Train data  : (15040, 2916)\n",
            "Test data   : (3760, 2916)\n",
            "Train labels: (15040,)\n",
            "Test labels : (3760,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGthxot5rzdc",
        "colab_type": "text"
      },
      "source": [
        "### Kiểm tra từng model và đánh giá model với tập test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjo2TwomB0Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a5baaa2-86c2-4040-c267-d6ff4a706fd7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "print(\"\\n=====================LogisticRegression======================\\n\")\n",
        "model1=LogisticRegression()\n",
        "model1.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred1 = model1.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred1))\n",
        "\n",
        "cnf_matrix1 = confusion_matrix(testLabelsGlobal, y_pred1)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix1)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred1)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "\n",
        "#####\n",
        "print(\"\\n=====================LinearDiscriminantAnalysis======================\\n\")\n",
        "model2=LinearDiscriminantAnalysis()\n",
        "model2.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred2 = model2.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred2))\n",
        "\n",
        "cnf_matrix2 = confusion_matrix(testLabelsGlobal, y_pred2)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix2)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred2)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "\n",
        "print(\"\\n=====================KNeighborsClassifier======================\\n\")\n",
        "\n",
        "####\n",
        "model3=KNeighborsClassifier(n_neighbors=5)\n",
        "model3.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred3 = model3.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred3))\n",
        "\n",
        "cnf_matrix3 = confusion_matrix(testLabelsGlobal, y_pred3)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix3)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred3)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "\n",
        "\n",
        "####\n",
        "print(\"\\n=====================DecisionTreeClassifier======================\\n\")\n",
        "\n",
        "model4= DecisionTreeClassifier()\n",
        "model4.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred4 = model4.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred4))\n",
        "\n",
        "cnf_matrix4 = confusion_matrix(testLabelsGlobal, y_pred4)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix4)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred4)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "\n",
        "\n",
        "###\n",
        "print(\"\\n=====================RandomForestClassifier======================\\n\")\n",
        "\n",
        "model5=RandomForestClassifier(n_estimators=100,random_state=0)\n",
        "model5.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred5 = model5.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred5))\n",
        "\n",
        "cnf_matrix5 = confusion_matrix(testLabelsGlobal, y_pred5)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix5)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred5)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall: {}'.format(recall))\n",
        "print('fscore: {}'.format(fscore))\n",
        "print('support: {}'.format(support))\n",
        "\n",
        "\n",
        "####\n",
        "print(\"\\n=====================GaussianNB======================\\n\")\n",
        "\n",
        "model6=GaussianNB()\n",
        "model6.fit(trainDataGlobal,trainLabelsGlobal)\n",
        "y_pred6 = model6.predict(testDataGlobal)\n",
        "print('accuracy = ',accuracy_score(testLabelsGlobal, y_pred6))\n",
        "\n",
        "cnf_matrix6 = confusion_matrix(testLabelsGlobal, y_pred6)\n",
        "print('Confusion matrix:')\n",
        "print(cnf_matrix6)\n",
        "# y_score = model1.decision_function(x_val)\n",
        "precision, recall, fscore, support = score(testLabelsGlobal, y_pred6)\n",
        "\n",
        "print('precision: {}'.format(precision))\n",
        "print('recall   : {}'.format(recall))\n",
        "print('fscore   : {}'.format(fscore))\n",
        "print('support  : {}'.format(support))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====================LogisticRegression======================\n",
            "\n",
            "accuracy =  1.0\n",
            "Confusion matrix:\n",
            "[[940   0   0   0]\n",
            " [  0 940   0   0]\n",
            " [  0   0 954   0]\n",
            " [  0   0   0 926]]\n",
            "precision: [1. 1. 1. 1.]\n",
            "recall: [1. 1. 1. 1.]\n",
            "fscore: [1. 1. 1. 1.]\n",
            "support: [940 940 954 926]\n",
            "\n",
            "=====================LinearDiscriminantAnalysis======================\n",
            "\n",
            "accuracy =  1.0\n",
            "Confusion matrix:\n",
            "[[940   0   0   0]\n",
            " [  0 940   0   0]\n",
            " [  0   0 954   0]\n",
            " [  0   0   0 926]]\n",
            "precision: [1. 1. 1. 1.]\n",
            "recall: [1. 1. 1. 1.]\n",
            "fscore: [1. 1. 1. 1.]\n",
            "support: [940 940 954 926]\n",
            "\n",
            "=====================KNeighborsClassifier======================\n",
            "\n",
            "accuracy =  1.0\n",
            "Confusion matrix:\n",
            "[[940   0   0   0]\n",
            " [  0 940   0   0]\n",
            " [  0   0 954   0]\n",
            " [  0   0   0 926]]\n",
            "precision: [1. 1. 1. 1.]\n",
            "recall: [1. 1. 1. 1.]\n",
            "fscore: [1. 1. 1. 1.]\n",
            "support: [940 940 954 926]\n",
            "\n",
            "=====================DecisionTreeClassifier======================\n",
            "\n",
            "accuracy =  0.9936170212765958\n",
            "Confusion matrix:\n",
            "[[938   0   2   0]\n",
            " [  5 932   0   3]\n",
            " [  2   3 946   3]\n",
            " [  2   1   3 920]]\n",
            "precision: [0.9904963  0.9957265  0.99474238 0.99352052]\n",
            "recall: [0.99787234 0.99148936 0.99161426 0.99352052]\n",
            "fscore: [0.99417064 0.99360341 0.99317585 0.99352052]\n",
            "support: [940 940 954 926]\n",
            "\n",
            "=====================RandomForestClassifier======================\n",
            "\n",
            "accuracy =  1.0\n",
            "Confusion matrix:\n",
            "[[940   0   0   0]\n",
            " [  0 940   0   0]\n",
            " [  0   0 954   0]\n",
            " [  0   0   0 926]]\n",
            "precision: [1. 1. 1. 1.]\n",
            "recall: [1. 1. 1. 1.]\n",
            "fscore: [1. 1. 1. 1.]\n",
            "support: [940 940 954 926]\n",
            "\n",
            "=====================GaussianNB======================\n",
            "\n",
            "accuracy =  0.9960106382978723\n",
            "Confusion matrix:\n",
            "[[940   0   0   0]\n",
            " [  3 934   0   3]\n",
            " [  1   2 946   5]\n",
            " [  0   1   0 925]]\n",
            "precision: [0.99576271 0.99679829 1.         0.99142551]\n",
            "recall   : [1.         0.99361702 0.99161426 0.99892009]\n",
            "fscore   : [0.99787686 0.99520511 0.99578947 0.99515869]\n",
            "support  : [940 940 954 926]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYmhVFFzsMnZ",
        "colab_type": "text"
      },
      "source": [
        "### Lưu model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7JaSY2nB2T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump\n",
        "dump(model2, 'weight2h.joblib') \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}